# ── Groq LLM ─────────────────────────────────────────────
GROQ_API_KEY=your-groq-api-key-here
MODEL_NAME=llama-3.3-70b-versatile

# ── Chroma Vector Database ────────────────────────────────
CHROMA_PERSIST_DIR=/data/chroma
CHROMA_COLLECTION=k8s_failures

# ── Embeddings (bge-small-en-v1.5 — 384-dim) ─────────────
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
EMBEDDING_DIMENSION=384
EMBEDDING_DEVICE=cpu          # cpu for Docker/Linux, mps for Apple Silicon

# ── Retrieval ─────────────────────────────────────────────
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
RETRIEVAL_TOP_K=4

# ── Memory ────────────────────────────────────────────────
MEMORY_PATH=/data/chat_memory.json

# ── Logging ───────────────────────────────────────────────
LOG_LEVEL=INFO
